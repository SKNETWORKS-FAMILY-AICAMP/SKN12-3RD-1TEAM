import sys
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import json 
import openai
from datetime import datetime
from langchain.chains.llm import LLMChain
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.tools import Tool
import re
from langchain.docstore.document import Document
import logging
import traceback
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from typing import List

# Add src to Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../src')))
import vector_manger as vm
from module import get_user_parser, get_category
from weather import get_weather, get_current_time
from fetch_pt_places import fetch_pet_friendly_places_only
from category_validator import CategoryValidator
from naver_map_utils import NaverMapUtils

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'log')
os.makedirs(log_dir, exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'chatbot.log')),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()
openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    logger.error("OPENAI_API_KEY not found in environment variables")
    raise ValueError("OPENAI_API_KEY is required")

# global variables
threshold = 5

def safe_fetch_pet_friendly_places(user_parsed, n):
    """
    API í˜¸ì¶œì„ ì•ˆì „í•˜ê²Œ ê°ì‹¸ê³  í•­ìƒ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì•ˆë‚´ ë©”ì‹œì§€ í¬í•¨.
    ìµœëŒ€ 3ë²ˆê¹Œì§€ ì¬ì‹œë„í•˜ì—¬ ìœ íš¨í•œ ì¥ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    MAX_RETRIES = 3
    
    # Input validation - check n first
    if not isinstance(n, int) or n <= 0:
        error_msg = "Invalid number of results requested"
        logger.error(error_msg)
        return [Document(page_content="ìš”ì²­ëœ ê²°ê³¼ ìˆ˜ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.", metadata={})]
        
    # Then check user_parsed
    if not user_parsed or not isinstance(user_parsed, dict):
        error_msg = "Invalid user_parsed parameter"
        logger.error(error_msg)
        return [Document(page_content="ì…ë ¥ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.", metadata={})]
    
    try:
        logger.info(f"Fetching pet friendly places for query: {user_parsed}")
        results = fetch_pet_friendly_places_only(user_parsed, n)
        docs = []
        
        for place in results or []:
            title = place.get('title', 'ì´ë¦„ ì—†ìŒ')
            logger.info(f"Processing place: {title}")
            
            # Validate place with Naver Maps
            if NaverMapUtils.is_valid_place(title):
                # Convert API result to Document
                content = title
                if place.get('addr1'):
                    content += f" - {place['addr1']}"
                if place.get('pet_info'):
                    content += f" (ë°˜ë ¤ë™ë¬¼: {place['pet_info']})"
                    
                metadata = {
                    "title": title,
                    "addr1": place.get('addr1', ''),
                    "pet_info": place.get('pet_info', ''),
                    "type": place.get('type', '')
                }
                
                docs.append(Document(page_content=content, metadata=metadata))
            else:
                logger.warning(f"Invalid place filtered out: {title}")
        
        if not docs:
            logger.warning("No valid places found in API results")
            docs.append(Document(page_content="í˜„ì¬ ìœ íš¨í•œ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", metadata={}))
            
        return docs
        
    except Exception as e:
        logger.error(f"API call failed: {str(e)}\n{traceback.format_exc()}")
        return [Document(page_content="ì™¸ë¶€ ë°ì´í„° í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", metadata={})]

def generate_transportation_rules(pet_type: str = None, transport_type: str = None) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë°˜ë ¤ë™ë¬¼ ëŒ€ì¤‘êµí†µ ì´ìš© ê·œì • ìƒì„±"""
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=openai_api_key
        )

        # êµí†µìˆ˜ë‹¨ í‚¤ì›Œë“œ ë§¤í•‘
        transport_keywords = {
            "ê¸°ì°¨": ["ê¸°ì°¨", "ktx", "ì—´ì°¨", "ì² ë„", "korail", "ì½”ë ˆì¼"],
            "ë²„ìŠ¤": ["ë²„ìŠ¤", "ì‹œë‚´ë²„ìŠ¤", "ì‹œì™¸ë²„ìŠ¤", "ê³ ì†ë²„ìŠ¤"],
            "ì§€í•˜ì² ": ["ì§€í•˜ì² ", "ì „ì² ", "metro"],
            "íƒì‹œ": ["íƒì‹œ", "call", "ì½œíƒì‹œ"]
        }

        # ì¿¼ë¦¬ì—ì„œ êµí†µìˆ˜ë‹¨ íƒ€ì… ì¶”ì¶œ
        if not transport_type:
            for t_type, keywords in transport_keywords.items():
                if any(keyword in query.lower() for keyword in keywords):
                    transport_type = t_type
                    break

        transport_template = PromptTemplate.from_template("""
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°˜ë ¤ë™ë¬¼ ëŒ€ì¤‘êµí†µ ì´ìš© ê·œì •ì„ ì•ˆë‚´í•´ì£¼ì„¸ìš”:
        ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜: {pet_type}
        êµí†µìˆ˜ë‹¨: {transport_type}

        ê·œì¹™:
        1. ì¹œê·¼í•˜ê³  ëª…í™•í•œ ë§íˆ¬ ì‚¬ìš©
        2. ì´ëª¨ì§€ ì ì ˆíˆ í™œìš©
        3. í•´ë‹¹ êµí†µìˆ˜ë‹¨ì˜ êµ¬ì²´ì ì¸ ê·œì •ë§Œ ì„¤ëª…
        4. ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œ ì£¼ì˜ì‚¬í•­ í¬í•¨
        5. í•„ìš”í•œ ì¤€ë¹„ë¬¼ ì•ˆë‚´

        {format_guide}
        """)

        # êµí†µìˆ˜ë‹¨ë³„ ì‘ë‹µ í¬ë§· ê°€ì´ë“œ
        format_guides = {
            "ê¸°ì°¨": """
            ì‘ë‹µ í˜•ì‹:
            ### ğŸš„ ê¸°ì°¨ ì´ìš© ì•ˆë‚´
            
            #### KTX/ì¼ë°˜ì—´ì°¨ ì´ìš© ê·œì •
            [êµ¬ì²´ì ì¸ ê·œì •]
            
            #### ì´ìš© ì‹œ ì£¼ì˜ì‚¬í•­
            [ì£¼ì˜ì‚¬í•­ ëª©ë¡]
            
            #### ì¤€ë¹„ë¬¼ ì•ˆë‚´
            [í•„ìš”í•œ ì¤€ë¹„ë¬¼ ëª©ë¡]
            """,
            "ë²„ìŠ¤": """
            ì‘ë‹µ í˜•ì‹:
            ### ğŸšŒ ë²„ìŠ¤ ì´ìš© ì•ˆë‚´
            
            #### ë²„ìŠ¤ ì´ìš© ê·œì •
            [êµ¬ì²´ì ì¸ ê·œì •]
            
            #### ì´ìš© ì‹œ ì£¼ì˜ì‚¬í•­
            [ì£¼ì˜ì‚¬í•­ ëª©ë¡]
            
            #### ì¤€ë¹„ë¬¼ ì•ˆë‚´
            [í•„ìš”í•œ ì¤€ë¹„ë¬¼ ëª©ë¡]
            """,
            "ì§€í•˜ì² ": """
            ì‘ë‹µ í˜•ì‹:
            ### ğŸš‡ ì§€í•˜ì²  ì´ìš© ì•ˆë‚´
            
            #### ì§€í•˜ì²  ì´ìš© ê·œì •
            [êµ¬ì²´ì ì¸ ê·œì •]
            
            #### ì´ìš© ì‹œ ì£¼ì˜ì‚¬í•­
            [ì£¼ì˜ì‚¬í•­ ëª©ë¡]
            
            #### ì¤€ë¹„ë¬¼ ì•ˆë‚´
            [í•„ìš”í•œ ì¤€ë¹„ë¬¼ ëª©ë¡]
            """,
            "íƒì‹œ": """
            ì‘ë‹µ í˜•ì‹:
            ### ğŸš• íƒì‹œ ì´ìš© ì•ˆë‚´
            
            #### íƒì‹œ ì´ìš© ê·œì •
            [êµ¬ì²´ì ì¸ ê·œì •]
            
            #### ì´ìš© ì‹œ ì£¼ì˜ì‚¬í•­
            [ì£¼ì˜ì‚¬í•­ ëª©ë¡]
            
            #### ì¤€ë¹„ë¬¼ ì•ˆë‚´
            [í•„ìš”í•œ ì¤€ë¹„ë¬¼ ëª©ë¡]
            """
        }

        # íŠ¹ì • êµí†µìˆ˜ë‹¨ì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ í¬ë§·ë§Œ ì‚¬ìš©
        format_guide = format_guides.get(transport_type, """
        ì‘ë‹µ í˜•ì‹:
        ### ğŸšŒ ëŒ€ì¤‘êµí†µ ì´ìš© ì•ˆë‚´
        
        #### ì´ìš© ê°€ëŠ¥í•œ êµí†µìˆ˜ë‹¨
        [êµí†µìˆ˜ë‹¨ë³„ ê·œì •]
        
        #### ì´ìš© ì‹œ ì£¼ì˜ì‚¬í•­
        [ì£¼ì˜ì‚¬í•­ ëª©ë¡]
        
        #### ì¤€ë¹„ë¬¼ ì•ˆë‚´
        [í•„ìš”í•œ ì¤€ë¹„ë¬¼ ëª©ë¡]
        """)

        chain = transport_template | llm | StrOutputParser()
        rules = chain.invoke({
            "pet_type": pet_type or "ë°˜ë ¤ë™ë¬¼",
            "transport_type": transport_type or "ëŒ€ì¤‘êµí†µ",
            "format_guide": format_guide
        })
        
        return rules.strip()
        
    except Exception as e:
        logger.error(f"Error generating transportation rules: {str(e)}")
        return """### ğŸšŒ ëŒ€ì¤‘êµí†µ ì´ìš© ì•ˆë‚´
        
ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ëŒ€ì¤‘êµí†µ ê·œì • ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜ ê° êµí†µìˆ˜ë‹¨ ìš´ì˜ê¸°ê´€ì— ì§ì ‘ ë¬¸ì˜í•´ì£¼ì„¸ìš”."""

def generate_travel_course(tourist_spots: List[Document], days: int = None, city: str = None) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì—¬í–‰ ì½”ìŠ¤ ìƒì„±"""
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=openai_api_key
        )

        # ê´€ê´‘ì§€ ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        spots_info = []
        for spot in tourist_spots:
            title = spot.metadata.get("title", "")
            addr = spot.metadata.get("addr1", "ì •ë³´ ì—†ìŒ")
            pet_info = spot.metadata.get("pet_info", "ì •ë³´ ì—†ìŒ")
            spots_info.append(f"{title} (ì£¼ì†Œ: {addr}, ë°˜ë ¤ë™ë¬¼: {pet_info})")

        course_template = PromptTemplate.from_template("""
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬í–‰ ì½”ìŠ¤ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        ë„ì‹œ: {city}
        ì—¬í–‰ ì¼ìˆ˜: {days}ì¼
        ë°©ë¬¸ ê°€ëŠ¥í•œ ê´€ê´‘ì§€ ëª©ë¡:
        {spots}

        ê·œì¹™:
        1. ê° ì¼ìë³„ë¡œ ì ì ˆí•œ ìˆ˜ì˜ ê´€ê´‘ì§€ ë°°ì¹˜
        2. ì´ë™ ë™ì„ ì„ ê³ ë ¤í•œ íš¨ìœ¨ì ì¸ ì½”ìŠ¤ êµ¬ì„±
        3. ì²´í¬ì¸/ì•„ì›ƒ ì‹œê°„ì„ ê³ ë ¤í•œ ì¼ì • ë°°ì¹˜
        4. ë°˜ë ¤ë™ë¬¼ ë™ë°˜ íŠ¹ì„±ì„ ê³ ë ¤í•œ ì½”ìŠ¤ êµ¬ì„±
        5. ê° ì¥ì†Œë³„ ì¶”ì²œ í¬ì¸íŠ¸ì™€ ì†Œìš”ì‹œê°„ í¬í•¨
        6. ê´€ê´‘ì§€ê°€ ë¶€ì¡±í•œ ê²½ìš° ì£¼ë³€ ì¶”ì²œ í™œë™ í¬í•¨
        7. í•˜ë£¨ ìµœëŒ€ 3-4ê³³ ë°©ë¬¸ ê¶Œì¥

        Few-shot ì˜ˆì‹œ:

        ì…ë ¥ ì˜ˆì‹œ 1:
        ë„ì‹œ: ì œì£¼ë„
        ì—¬í–‰ ì¼ìˆ˜: 3ì¼
        ê´€ê´‘ì§€: í˜‘ì¬í•´ìˆ˜ìš•ì¥, í•œë¼ì‚°, ì„±ì‚°ì¼ì¶œë´‰, ì¹´í˜ê±°ë¦¬, ì˜¬ë ˆê¸¸

        ì¶œë ¥ ì˜ˆì‹œ 1:
        ### ğŸ¯ ì¶”ì²œ ì—¬í–‰ ì½”ìŠ¤
        ì—¬í–‰ì˜ ì¦ê±°ì›€ì„ ë”í•  ìˆ˜ ìˆëŠ” ì½”ìŠ¤ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!

        #### ğŸŒ… 1ì¼ì°¨
        ì²«ì§¸ ë‚ ì€ ë„ì°© í›„ ì—¬ìœ ë¡œìš´ ì¼ì •ìœ¼ë¡œ ì‹œì‘í•´ë³´ì„¸ìš”!
        
        ##### í˜‘ì¬í•´ìˆ˜ìš•ì¥
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ í•´ë³€ ì‚°ì±…ì„ ì¦ê¸°ê¸° ì¢‹ì€ ì˜¤í›„ ì‹œê°„ëŒ€ ë°©ë¬¸ ì¶”ì²œ
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 1-2ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ: ê·¼ì²˜ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì¹´í˜ì—ì„œ íœ´ì‹
        
        ##### ì¹´í˜ê±°ë¦¬
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ ì¹´í˜ì—ì„œ ì—¬ìœ ë¡œìš´ íœ´ì‹
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 1-2ì‹œê°„

        #### ğŸŒ… 2ì¼ì°¨        
        ##### ì„±ì‚°ì¼ì¶œë´‰
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ì•„ì¹¨ ì¼ì¶œ ëª…ì†Œ, ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜í•˜ëŠ” íŠ¸ë ˆí‚¹
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 2-3ì‹œê°„
        
        ##### ì˜¬ë ˆê¸¸
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜í•˜ëŠ” ì—¬ìœ ë¡œìš´ ì˜¬ë ˆê¸¸ ì‚°ì±…
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 2-3ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ: ì˜¬ë ˆê¸¸ ì£¼ë³€ í¬í† ìŠ¤íŒŸì—ì„œ ì¸ìƒìƒ·

        #### ğŸŒ… 3ì¼ì°¨
        ë§ˆì§€ë§‰ ë‚ ì€ ì²´í¬ì•„ì›ƒ ì‹œê°„ì„ ê³ ë ¤í•œ ì¼ì •ì…ë‹ˆë‹¤.
        
        ##### í•œë¼ì‚°
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ì˜¤ì „ì— ë°©ë¬¸í•˜ì—¬ ë‚ ì”¨ ì¢‹ì„ ë•Œ ì‚°ì±…ë¡œ ì½”ìŠ¤ ì¶”ì²œ
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 2-3ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ: ê·¼ì²˜ ì „ë§ ì¢‹ì€ ì¹´í˜ì—ì„œ ë§ˆë¬´ë¦¬

        ì…ë ¥ ì˜ˆì‹œ 2:
        ë„ì‹œ: ê²½ì£¼
        ì—¬í–‰ ì¼ìˆ˜: 2ì¼
        ê´€ê´‘ì§€: ì‹ ë¼ì™•ê²½ìˆ²

        ì¶œë ¥ ì˜ˆì‹œ 2:
        ### ğŸ¯ ì¶”ì²œ ì—¬í–‰ ì½”ìŠ¤
        ì—¬í–‰ì˜ ì¦ê±°ì›€ì„ ë”í•  ìˆ˜ ìˆëŠ” ì½”ìŠ¤ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!

        #### ğŸŒ… 1ì¼ì°¨
        ì²«ì§¸ ë‚ ì€ ë„ì°© í›„ ì—¬ìœ ë¡œìš´ ì¼ì •ìœ¼ë¡œ ì‹œì‘í•´ë³´ì„¸ìš”!
        
        ##### ì‹ ë¼ì™•ê²½ìˆ² (ì˜¤í›„)
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ë„“ì€ ìˆ²ì†ì—ì„œ ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ì‚°ì±…í•˜ê¸° ì¢‹ì€ ì¥ì†Œ
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 2-3ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ: 
          * ê·¼ì²˜ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì¹´í˜ì—ì„œ íœ´ì‹
          * í™©ë¦¬ë‹¨ê¸¸ ì‚°ì±…
          * ë™ê¶ê³¼ ì›”ì§€(ì•ˆì••ì§€) ì•¼ê²½ ê°ìƒ

        #### ğŸŒ… 2ì¼ì°¨
        ë§ˆì§€ë§‰ ë‚ ì€ ì²´í¬ì•„ì›ƒ ì‹œê°„ì„ ê³ ë ¤í•œ ì¼ì •ì…ë‹ˆë‹¤.
        
        ##### ì‹ ë¼ì™•ê²½ìˆ² (ì•„ì¹¨)
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ì•„ì¹¨ ì‚°ì±…ìœ¼ë¡œ ìƒì¾Œí•œ í•˜ë£¨ ì‹œì‘
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 1-2ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ:
          * ì²¨ì„±ëŒ€ ì£¼ë³€ ì‚°ì±…
          * ëŒ€ë¦‰ì› ëŒë‹´ê¸¸ ì‚°ì±…
          * ì¹´í˜ê±°ë¦¬ì—ì„œ ë¸ŒëŸ°ì¹˜

        ì…ë ¥ ì˜ˆì‹œ 3:
        ë„ì‹œ: ì†ì´ˆ
        ì—¬í–‰ ì¼ìˆ˜: 1ì¼
        ê´€ê´‘ì§€: ì™¸ì˜¹ì¹˜í•´ë³€, ëŒ€í¬í•­

        ì¶œë ¥ ì˜ˆì‹œ 3:
        ### ğŸ¯ ì¶”ì²œ ì—¬í–‰ ì½”ìŠ¤
        ì—¬í–‰ì˜ ì¦ê±°ì›€ì„ ë”í•  ìˆ˜ ìˆëŠ” ì½”ìŠ¤ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!

        #### ğŸŒ… ë‹¹ì¼ ì½”ìŠ¤
        ##### ì™¸ì˜¹ì¹˜í•´ë³€ (ì˜¤ì „)
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ì•„ì¹¨ ë°”ë‹¤ ì‚°ì±…ê³¼ ì¼ì¶œ ê°ìƒ
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 1-2ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ: í•´ë³€ ì¹´í˜ì—ì„œ ëª¨ë‹ì»¤í”¼
        
        ##### ëŒ€í¬í•­ (ì ì‹¬~ì˜¤í›„)
        - ğŸ’¡ ì¶”ì²œ í¬ì¸íŠ¸: ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜í•˜ëŠ” í•­êµ¬ ì‚°ì±…
        - â° ì¶”ì²œ ì†Œìš”ì‹œê°„: 2-3ì‹œê°„
        - ğŸ” ì£¼ë³€ ì¶”ì²œ:
          * ëŒ€í¬í•­ ìˆ˜ì‚°ì‹œì¥ êµ¬ê²½
          * ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ íšŸì§‘
          * ë“±ëŒ€ ì „ë§ëŒ€ ì‚°ì±…

        ì‹¤ì œ ì‘ë‹µì„ ìœ„í•œ í˜•ì‹:
        ### ğŸ¯ ì¶”ì²œ ì—¬í–‰ ì½”ìŠ¤
        ì—¬í–‰ì˜ ì¦ê±°ì›€ì„ ë”í•  ìˆ˜ ìˆëŠ” ì½”ìŠ¤ë¥¼ ì¶”ì²œí•´ë“œë¦½ë‹ˆë‹¤!

        [ì¼ìë³„ ì½”ìŠ¤ êµ¬ì„±]
        """)

        chain = course_template | llm | StrOutputParser()
        course = chain.invoke({
            "city": city or "ì—¬í–‰ì§€",
            "days": days or 1,
            "spots": "\n".join(spots_info)
        })
        
        return course.strip()
        
    except Exception as e:
        logger.error(f"Error generating travel course: {str(e)}")
        return """### ğŸ¯ ì¶”ì²œ ì—¬í–‰ ì½”ìŠ¤
        
ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì—¬í–‰ ì½”ìŠ¤ ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê±°ë‚˜ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì•ˆë‚´í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤."""

def generate_category_content(results, user_categories, city, query: str = ""):
    """ì¹´í…Œê³ ë¦¬ë³„ ì»¨í…ì¸  ìƒì„±"""
    logger.info(f"Generating content for categories: {user_categories} in city: {city}")
    content_sections = []
    
    # ì¸ì‚¬ë§ ë° ìš”ì•½ ìƒì„±
    greeting = generate_greeting(city, user_categories)
    content_sections.append(f"### {greeting}\n")
    
    # ëŒ€ì¤‘êµí†µ ì •ë³´ ì²˜ë¦¬
    if "ëŒ€ì¤‘êµí†µ" in user_categories:
        # ì¿¼ë¦¬ì—ì„œ ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ ì¶”ì¶œ (ì˜ˆ: "ë¦¬íŠ¸ë¦¬ë²„")
        pet_type = None
        for keyword in ["ë¦¬íŠ¸ë¦¬ë²„", "í‘¸ë“¤", "ë§í‹°ì¦ˆ", "ì¹˜ì™€ì™€", "í¬ë©”ë¼ë‹ˆì•ˆ"]:  # í•„ìš”í•œ ê²¬ì¢… ì¶”ê°€
            if keyword.lower() in query.lower():
                pet_type = keyword
                break
        transport_rules = generate_transportation_rules(pet_type)
        content_sections.append(transport_rules)
    
    # ë‚ ì”¨ ì •ë³´ ì²˜ë¦¬
    if "ë‚ ì”¨" in user_categories and city:
        try:
            weather = get_weather(city)
            if "error" not in weather:
                weather_info = (
                    "### ë‚ ì”¨ ì •ë³´\n"
                    f"- ë„ì‹œ: {weather['city']}\n"
                    f"- ê¸°ì˜¨: {weather['temperature']}Â°C\n"
                    f"- ìŠµë„: {weather['humidity']}%\n"
                    f"- ê°•ìˆ˜í˜•íƒœ: {weather['precipitation_type']}\n"
                )
                content_sections.append(weather_info)
            else:
                content_sections.append("### ë‚ ì”¨ ì •ë³´\ní˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
        except Exception as e:
            logger.error(f"Weather fetch failed: {str(e)}")
            content_sections.append("### ë‚ ì”¨ ì •ë³´\ní˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")
    
    # ì—¬í–‰ ì½”ìŠ¤ ì¶”ì²œ ì„¹ì…˜ ì¶”ê°€
    if "ê´€ê´‘ì§€" in user_categories:
        tourist_spots = []
        if "ê´€ê´‘ì§€" in results:
            for place in results["ê´€ê´‘ì§€"]:
                if isinstance(place, Document):
                    tourist_spots.append(place)
        
        if tourist_spots:
            # ì—¬í–‰ ì¼ìˆ˜ í™•ì¸
            days = None
            try:
                days_match = re.search(r'(\d+)ë°•', query)
                if days_match:
                    days = int(days_match.group(1)) + 1  # Në°•ì˜ ê²½ìš° N+1ì¼
            except:
                days = None
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì—¬í–‰ ì½”ìŠ¤ ìƒì„±
            course_content = generate_travel_course(tourist_spots, days, city)
            content_sections.append(course_content)
            
            # ì—¬í–‰ íŒ ì¶”ê°€
            content_sections.append("\n#### âœ¨ ì—¬í–‰ íŒ")
            content_sections.append("- ğŸ• ê° ê´€ê´‘ì§€ë§ˆë‹¤ ì¶”ì²œ ì†Œìš”ì‹œê°„ì„ ì°¸ê³ í•˜ì—¬ ì—¬ìœ ìˆê²Œ ì¼ì •ì„ ì¡ìœ¼ì„¸ìš”.")
            content_sections.append("- ğŸ• ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜í•  ë•ŒëŠ” ëª©ì¤„ê³¼ ë°°ë³€ë´‰íˆ¬ë¥¼ í•„ìˆ˜ë¡œ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
            content_sections.append("- ğŸ“¸ ì¸ìƒìƒ· ìŠ¤íŒŸì´ ë§ìœ¼ë‹ˆ ì¹´ë©”ë¼ ì¤€ë¹„ í•„ìˆ˜!")
            content_sections.append("- ğŸš— ì£¼ì°¨ ê³µê°„ì´ ìˆëŠ”ì§€ ë¯¸ë¦¬ í™•ì¸í•˜ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.")
            if days and days > 1:
                content_sections.append("- ğŸ¨ ì²´í¬ì¸/ì²´í¬ì•„ì›ƒ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ì¼ì •ì„ ì¡°ìœ¨í•˜ì„¸ìš”.")
                content_sections.append("- ğŸŒ¦ï¸ ë‚ ì”¨ë¥¼ ë¯¸ë¦¬ í™•ì¸í•˜ê³  ì¼ì •ì„ ìœ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì„¸ìš”.")
    
    # ìˆ™ë°• ì •ë³´ ì²˜ë¦¬
    if "ìˆ™ë°•" in user_categories:
        content_sections.append("\n### ğŸ¨ ìˆ™ë°• ì •ë³´")
        if "ìˆ™ë°•" in results and results["ìˆ™ë°•"]:
            for place in results["ìˆ™ë°•"]:
                if isinstance(place, Document):
                    title = place.metadata.get("title", "")
                    addr = place.metadata.get("addr1", "ì •ë³´ ì—†ìŒ")
                    pet_info = place.metadata.get("pet_info", "ì •ë³´ ì—†ìŒ")
                    map_link = NaverMapUtils.get_map_link(title)
                    
                    accommodation_info = [
                        f"#### {title}",
                        f"- ğŸ“ [ë„¤ì´ë²„ ì§€ë„]({map_link})",
                        f"- ğŸ  ì£¼ì†Œ: {addr}",
                        f"- ğŸ• ë°˜ë ¤ë™ë¬¼: {pet_info}",
                        f"- ğŸ’¡ ìˆ™ì†Œ íŠ¹ì§•: {get_accommodation_highlight(title)}\n"
                    ]
                    content_sections.append("\n".join(accommodation_info))
            
            # ìˆ™ë°• íŒ ì¶”ê°€
            content_sections.append("\n#### âœ¨ ìˆ™ë°• íŒ")
            content_sections.append("- ğŸ• ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œ ë¯¸ë¦¬ ì˜ˆì•½í•˜ì‹œëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.")
            content_sections.append("- ğŸ“ ì²´í¬ì¸ ì‹œê°„ì„ ë¯¸ë¦¬ í™•ì¸í•˜ì„¸ìš”.")
            content_sections.append("- ğŸ§¹ ë°˜ë ¤ë™ë¬¼ ìš©í’ˆ(ë°©ì„, ë°°ë³€íŒ¨ë“œ ë“±)ì„ ì¤€ë¹„í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.")
        else:
            content_sections.append("í˜„ì¬ ì´ìš© ê°€ëŠ¥í•œ ìˆ™ë°• ì‹œì„¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    return "\n".join(content_sections)

def get_spot_highlight(spot_name: str) -> str:
    """ê´€ê´‘ì§€ë³„ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ë°˜í™˜"""
    highlights = {
        "ì™¸ì˜¹ì¹˜í•´ë³€": "ì•„ë¦„ë‹¤ìš´ ì¼ì¶œ ëª…ì†Œì´ë©°, ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ì‚°ì±…í•˜ê¸° ì¢‹ì€ í•´ë³€ì…ë‹ˆë‹¤. íŠ¹íˆ ì•„ì¹¨ ì‹œê°„ëŒ€ ë°©ë¬¸ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
        "ëŒ€í¬í•­": "ì‹ ì„ í•œ í•´ì‚°ë¬¼ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê³³ìœ¼ë¡œ, ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ì—¬ìœ ë¡œìš´ ì‚°ì±…ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì¼ëª° ì‹œê°„ëŒ€ê°€ íŠ¹íˆ ì•„ë¦„ë‹µìŠµë‹ˆë‹¤.",
        "ì˜ê¸ˆì •": "ì†ì´ˆ ì‹œë‚´ê°€ í•œëˆˆì— ë³´ì´ëŠ” ì „ë§ ëª…ì†Œë¡œ, ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ì¸ìƒìƒ·ì„ ë‚¨ê¸°ê¸° ì¢‹ì€ ì¥ì†Œì…ë‹ˆë‹¤."
    }
    return highlights.get(spot_name, "ì•„ë¦„ë‹¤ìš´ ê²½ê´€ê³¼ í•¨ê»˜ ë°˜ë ¤ë™ë¬¼ê³¼ íŠ¹ë³„í•œ ì¶”ì–µì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì¥ì†Œì…ë‹ˆë‹¤.")

def get_accommodation_highlight(accommodation_name: str) -> str:
    """ìˆ™ì†Œë³„ í•˜ì´ë¼ì´íŠ¸ ì •ë³´ ë°˜í™˜"""
    highlights = {
        "ì„¤ì•…ê¸ˆí˜¸ë¦¬ì¡°íŠ¸": "ë°˜ë ¤ë™ë¬¼ ì „ìš© ìš©í’ˆì´ êµ¬ë¹„ë˜ì–´ ìˆìœ¼ë©°, ì£¼ë³€ ì‚°ì±…ë¡œê°€ ì˜ ì¡°ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 8kg ì´í•˜ ì†Œí˜•ê²¬ ë™ë°˜ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    }
    return highlights.get(accommodation_name, "ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ í¸ì•ˆí•œ íœ´ì‹ì„ ì·¨í•  ìˆ˜ ìˆëŠ” ìˆ™ì†Œì…ë‹ˆë‹¤.")

def create_dynamic_prompt(query: str, user_categories: list):
    """ì‚¬ìš©ì ì§ˆë¬¸ ì˜ë„ì— ë§ëŠ” ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì‘ë‹µ í˜•ì‹ê³¼ ì§€ì‹œì‚¬í•­
    category_formats = {
        "ê´€ê´‘ëª…ì†Œ": {
            "single": "ê´€ê´‘ì§€ ì •ë³´ì™€ ì¶”ì²œ ì½”ìŠ¤ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "combined": "ê´€ê´‘ì§€ ì¶”ì²œê³¼ ë°©ë¬¸ ìˆœì„œë¥¼ ê³„íšì— í¬í•¨í•´ì£¼ì„¸ìš”."
        },
        "ìˆ™ë°•": {
            "single": "ìˆ™ë°• ì‹œì„¤ ì •ë³´ì™€ ì˜ˆì•½ ì‹œ ì£¼ì˜ì‚¬í•­ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "combined": "ìˆ™ë°• ì‹œì„¤ ì¶”ì²œê³¼ ì˜ˆì•½ ê´€ë ¨ ì •ë³´ë¥¼ ê³„íšì— í¬í•¨í•´ì£¼ì„¸ìš”."
        },
        "ëŒ€ì¤‘êµí†µ": {
            "single": "ëŒ€ì¤‘êµí†µ ì´ìš© ë°©ë²•ê³¼ ê·œì •ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "combined": "ëŒ€ì¤‘êµí†µ ì´ìš© ë°©ë²•ê³¼ ì£¼ì˜ì‚¬í•­ì„ ê³„íšì— í¬í•¨í•´ì£¼ì„¸ìš”."
        },
        "ë‚ ì”¨": {
            "single": "í˜„ì¬ ë‚ ì”¨ ìƒí™©ê³¼ ì—¬í–‰ ì‹œ ì£¼ì˜ì‚¬í•­ì„ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "combined": "ë‚ ì”¨ì— ë”°ë¥¸ ì—¬í–‰ íŒê³¼ ì¤€ë¹„ë¬¼ì„ ê³„íšì— í¬í•¨í•´ì£¼ì„¸ìš”."
        }
    }
    
    # ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ì‘ë‹µì¸ì§€ í™•ì¸
    is_single_category = len(user_categories) == 1
    
    instructions = []
    format_type = "single" if is_single_category else "combined"
    
    # ì¹´í…Œê³ ë¦¬ë³„ ì§€ì‹œì‚¬í•­ ì¶”ê°€
    for category in user_categories:
        if category in category_formats:
            instructions.append(category_formats[category][format_type])
    
    # ê¸°ë³¸ ì‘ë‹µ í˜•ì‹ ì§€ì •
    response_format = [
        "",
        "ì‘ë‹µ í˜•ì‹:",
        "1. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±",
        "2. ê° ì¹´í…Œê³ ë¦¬ë¥¼ ëª…í™•íˆ êµ¬ë¶„",
        "3. êµ¬ì²´ì ì¸ ì •ë³´ì™€ ê·¼ê±° í¬í•¨",
        "4. ì‹¤ì œ ì¥ì†Œëª…ê³¼ ë°ì´í„° í™œìš©"
    ]
    
    # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•©
    prompt_parts = [
        f"ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”: {query}",
        "ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í¬í•¨í•˜ì—¬ ì‘ë‹µí•´ì£¼ì„¸ìš”:",
        *instructions,
        *response_format
    ]
    
    return "\n".join(prompt_parts)

def process_query(query: str, stream: bool = True):
    """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (API/DB ì•ˆì •ì„± ê°•í™”)"""
    logger.info(f"Processing query: {query}")
    
    try:
        # 1. ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±
        user_parsed = get_user_parser(query)
        if not user_parsed:
            raise ValueError("Failed to parse user query")
            
        user_categories = get_category(query)
        if not user_categories:
            raise ValueError("Failed to identify categories from query")
            
        city = user_parsed.get("region", "")
        logger.info(f"Parsed query - Categories: {user_categories}, City: {city}")
        
        # ëŒ€ì¤‘êµí†µ ì¹´í…Œê³ ë¦¬ë§Œ ìˆëŠ” ê²½ìš° ë°”ë¡œ LLM ì‘ë‹µ
        if len(user_categories) == 1 and "ëŒ€ì¤‘êµí†µ" in user_categories:
            # ë°˜ë ¤ë™ë¬¼ ì¢…ë¥˜ ì¶”ì¶œ
            pet_type = None
            for keyword in ["ë¦¬íŠ¸ë¦¬ë²„", "í‘¸ë“¤", "ë§í‹°ì¦ˆ", "ì¹˜ì™€ì™€", "í¬ë©”ë¼ë‹ˆì•ˆ"]:
                if keyword.lower() in query.lower():
                    pet_type = keyword
                    break
            
            # êµí†µìˆ˜ë‹¨ íƒ€ì… ì¶”ì¶œ
            transport_type = None
            transport_keywords = {
                "ê¸°ì°¨": ["ê¸°ì°¨", "ktx", "ì—´ì°¨", "ì² ë„", "korail", "ì½”ë ˆì¼"],
                "ë²„ìŠ¤": ["ë²„ìŠ¤", "ì‹œë‚´ë²„ìŠ¤", "ì‹œì™¸ë²„ìŠ¤", "ê³ ì†ë²„ìŠ¤"],
                "ì§€í•˜ì² ": ["ì§€í•˜ì² ", "ì „ì² ", "metro"],
                "íƒì‹œ": ["íƒì‹œ", "call", "ì½œíƒì‹œ"]
            }
            
            for t_type, keywords in transport_keywords.items():
                if any(keyword in query.lower() for keyword in keywords):
                    transport_type = t_type
                    break
            
            # ì¸ì‚¬ë§ ìƒì„±
            greeting = generate_greeting(city, user_categories)
            # ëŒ€ì¤‘êµí†µ ê·œì • ìƒì„±
            transport_rules = generate_transportation_rules(pet_type, transport_type)
            
            # ëŒ€ì¤‘êµí†µ ì¹´í…Œê³ ë¦¬ë§Œ ìˆëŠ” ê²½ìš° ë°”ë¡œ ë°˜í™˜
            return f"### {greeting}\n\n{transport_rules}"

        # 2. ìˆ™ë°•/ê´€ê´‘ì§€ ê´€ë ¨ ê²€ìƒ‰ì¼ ê²½ìš°ì—ë§Œ ë²¡í„° ê²€ìƒ‰ ë° API í˜¸ì¶œ
        combined_results = {"ê´€ê´‘ì§€": [], "ìˆ™ë°•": []}
        if any(category in ["ìˆ™ë°•", "ê´€ê´‘ì§€"] for category in user_categories):
            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            vector_results = vm.multiretrieve_by_category(query, user_categories)
            logger.info(f"Vector search results: {vector_results}")
            
            # API ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            api_results = safe_fetch_pet_friendly_places(user_parsed, 5)
            logger.info(f"API results: {api_results}")
            
            # ê²°ê³¼ í†µí•© ë° ê²€ì¦
            for category in ["ìˆ™ë°•", "ê´€ê´‘ì§€"]:
                if category in user_categories:
                    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
                    if category in vector_results:
                        for doc in vector_results[category]:
                            title = doc.metadata.get("title", "")
                            if title and NaverMapUtils.is_valid_place(title):
                                combined_results[category].append(doc)
                    
                    # API ê²°ê³¼ ì²˜ë¦¬
                    for place in api_results:
                        if isinstance(place, Document):
                            title = place.metadata.get("title", "").lower()
                            
                            # ìˆ™ë°• ì‹œì„¤ í‚¤ì›Œë“œ
                            accommodation_keywords = [
                                "ë¦¬ì¡°íŠ¸", "í˜¸í…”", "ìˆ™ì†Œ", "íœì…˜", "ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤", 
                                "ë¯¼ë°•", "ì½˜ë„", "ëª¨í…”", "ìˆ™ë°•", "ìŠ¤í…Œì´", "ë ˆì§€ë˜ìŠ¤",
                                "í•˜ìš°ìŠ¤", "ë¹Œë¼", "ë£¸", "ìŠ¤ìœ„íŠ¸", "ìº í•‘", "park",
                                "ê¸€ë¨í•‘", "camping"
                            ]
                            
                            # ê´€ê´‘ì§€ í‚¤ì›Œë“œ
                            tourist_keywords = [
                                "í•´ë³€", "í•­", "ê³µì›", "ì˜¤ë¦„", "í­í¬", "ê³„ê³¡", 
                                "ë™êµ´", "ì‚°", "ìˆ²", "ì •", "ë†ì¥", "ë°•ë¬¼ê´€", 
                                "ë¯¸ìˆ ê´€", "ì„±", "ì ˆ", "ìœ ì ", "ì „ë§ëŒ€", "ë‹¨ì§€",
                                "ê±°ë¦¬", "ë§ˆì„", "ë¦‰", "ê¶", "ê¸¸", "ê´€ê´‘"
                            ]
                            
                            # ì¥ì†Œ ë¶„ë¥˜
                            if category == "ìˆ™ë°•" and any(keyword in title for keyword in accommodation_keywords):
                                place.metadata["type"] = "ìˆ™ë°•"
                                if title not in [doc.metadata.get("title", "") for doc in combined_results["ìˆ™ë°•"]]:
                                    combined_results["ìˆ™ë°•"].append(place)
                            elif category == "ê´€ê´‘ì§€" and any(keyword in title for keyword in tourist_keywords):
                                place.metadata["type"] = "ê´€ê´‘ì§€"
                                if title not in [doc.metadata.get("title", "") for doc in combined_results["ê´€ê´‘ì§€"]]:
                                    combined_results["ê´€ê´‘ì§€"].append(place)
                            elif category == "ê´€ê´‘ì§€":  # í‚¤ì›Œë“œì— ì—†ëŠ” ê´€ê´‘ì§€ë„ í¬í•¨
                                place.metadata["type"] = "ê´€ê´‘ì§€"
                                if title not in [doc.metadata.get("title", "") for doc in combined_results["ê´€ê´‘ì§€"]]:
                                    combined_results["ê´€ê´‘ì§€"].append(place)
        
        # ì»¨í…ì¸  ìƒì„±
        content = generate_category_content(combined_results, user_categories, city, query)
        
        # ê²€ì¦ëœ ì¥ì†Œê°€ ì—†ëŠ” ê²½ìš° ë©”ì‹œì§€ ì¶”ê°€
        if any(category in ["ìˆ™ë°•", "ê´€ê´‘ì§€"] for category in user_categories):
            total_places = sum(len(places) for category, places in combined_results.items())
            if total_places == 0:
                content = "### ì•ˆë‚´\nê²€ì¦ëœ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n" + content
        
        return content
        
    except Exception as e:
        logger.error(f"Error processing query: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."


# ì¼ë°˜ì ì¸ ëŒ€í™” ë‚´ìš© ìƒì„± 
def check_greeting(query: str) -> str:
    """ì¼ë°˜ì ì¸ ëŒ€í™” ë‚´ìš© ìƒì„±"""
    greetings = ['ì•ˆë…•', 'hello', 'ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°€ì›Œ', 'í•˜ì´', 'hi']
    thanks = ['ê°ì‚¬í•©ë‹ˆë‹¤', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ê³ ë§ˆì›Œìš”', 'ê°ì‚¬í•©ë‹ˆë‹¤', 'ê³ ë§ˆì›Œìš”']
    help_words = ["ë„ì›€", "ì–´ë–»ê²Œ ì¨", "ë¬´ìŠ¨ ê¸°ëŠ¥", "ì„¤ëª…í•´ì¤˜"]
    query = query.lower()
    
    # if any(greeting in query for greeting in greetings):
        # return "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ğŸ¶ ë°˜ë ¤ë™ë¬¼ê³¼ í•¨ê»˜ ì—¬í–‰ ë„ ì›€ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    if any(word in query for word in greetings):
        return "ì•ˆë…•í•˜ì„¸ìš”! ì—¬í–‰ ê´€ë ¨í•´ì„œ ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš” ğŸ˜Š" # ì¸ì‚¬ì‘ë‹µ
    elif any(word in query for word in thanks):
        return "ì–¸ì œë“ ì§€ ë„ì™€ë“œë¦´ê²Œìš”! ë˜ ê¶ê¸ˆí•œ ê±° ìˆìœ¼ì‹ ê°€ìš”?" # ê°ì‚¬ì‘ë‹µ
    elif any(word in query for word in help_words):
        return "ì´ ì±—ë´‡ì€ ì—¬í–‰ ì½”ìŠ¤ ì¶”ì²œ, ìˆ™ë°• ì •ë³´, ëŒ€ì¤‘êµí†µ ê·œì • ì•ˆë‚´ë¥¼ ë„ì™€ë“œë ¤ìš”. ì˜ˆ: 'ì œì£¼ë„ ì—¬í–‰ ì¶”ì²œí•´ì¤˜'" # ë„ì›€ë§ ì‘ë‹µ
    else:
        return  None # ì´ë˜ì•¼ ëŒ€í™”ê°€ ê³„ì† ì§„í–‰ë¨

def generate_greeting(city: str, categories: List[str]) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ì¸ì‚¬ë§ ìƒì„±"""
    try:
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.3,
            api_key=openai_api_key
        )

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
        greeting_template = PromptTemplate.from_template("""
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì—¬í–‰ ì•ˆë‚´ ì¸ì‚¬ë§ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
        ë„ì‹œ: {city}
        ì¹´í…Œê³ ë¦¬: {categories}

        ê·œì¹™:
        1. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬ ì‚¬ìš©
        2. ì´ëª¨ì§€ ì ì ˆíˆ í™œìš©
        3. í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨í•˜ê²Œ ì‘ì„±
        4. ì¹´í…Œê³ ë¦¬ê°€ ì—¬ëŸ¬ ê°œë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë‚˜ì—´
        5. "ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤"ë¡œ ëë‚˜ë„ë¡ ì‘ì„±

        ì˜ˆì‹œ:
        - ëŒ€êµ¬ì˜ ë§›ì§‘ê³¼ ê´€ê´‘ ì •ë³´ë¥¼ í•œ ë²ˆì— ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ğŸŒŸ
        - ì œì£¼ë„ì˜ ìˆ™ë°•, ê´€ê´‘ ë° ë‚ ì”¨ ì •ë³´ë¥¼ ìƒì„¸íˆ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ âœ¨
        - ë¶€ì‚°ì˜ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ í•´ìˆ˜ìš•ì¥ ì •ë³´ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ğŸ–

        ì‘ë‹µ:
        """)

        # ì¹´í…Œê³ ë¦¬ ë¬¸ìì—´ ìƒì„±
        categories_str = json.dumps(categories, ensure_ascii=False) if categories else "[]"
        
        # LLM ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
        chain = greeting_template | llm | StrOutputParser()
        greeting = chain.invoke({
            "city": city or "ì „êµ­",
            "categories": categories_str
        })
        
        return greeting.strip()
        
    except Exception as e:
        logger.error(f"Error generating greeting: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì¸ì‚¬ë§ ë°˜í™˜
        if city:
            return f"{city} ì—¬í–‰ ì •ë³´ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ğŸ–"
        return "ì—¬í–‰ ì •ë³´ë¥¼ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ğŸŒŸ"



# ì‹¤í–‰ ì˜ˆì‹œ
# if __name__ == "__main__":
#     logger.info("Starting test queries")
#     # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì˜ˆì‹œë“¤
#     test_queries = [
#         "ì†ì´ˆë¡œ ì—¬í–‰ê°ˆë ¤ê³ í•˜ëŠ”ë° ë²„ìŠ¤ ê·œì •ì´ ì–´ë–»ê²Œë¼?",  # ëŒ€ì¤‘êµí†µë§Œ
#         "ì†ì´ˆì˜ ë‚ ì”¨ ì–´ë•Œ?",  # ë‚ ì”¨ë§Œ
#         "ì†ì´ˆ ë²„ìŠ¤ë¡œ ì—¬í–‰ê°ˆë ¤ê³ í•˜ëŠ”ë° í˜„ì¬ ë‚ ì”¨ëŠ”?",  # ë‚ ì”¨ + ëŒ€ì¤‘êµí†µ
#         "ì†ì´ˆ ìˆ™ë°•ì‹œì„¤ ì¶”ì²œí•´ì¤˜",  # ìˆ™ë°•ë§Œ
#         "ì†ì´ˆ ê´€ê´‘ì§€ ì¶”ì²œ"  # ê´€ê´‘ë§Œ
#     ]
    
#     # ë‹¨ìœ„ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì¶œë ¥ 
#     for query in test_queries:
#         try:
#             logger.info(f"Testing query: {query}")
#             result = process_query(query, stream=False)
#             logger.info(f"Query successful: {query}")
#             print(f"ì§ˆë¬¸: {query}")
#             print(f"ê²°ê³¼: {result}")
#             print('-'*50)
#         except Exception as e:
#             logger.error(f"Test query failed: {query}\n{str(e)}\n{traceback.format_exc()}")